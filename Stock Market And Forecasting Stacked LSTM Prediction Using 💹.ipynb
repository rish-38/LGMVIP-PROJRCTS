{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market And Forecasting Stacked LSTM Prediction Using ðŸ’¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset and preprocess it\n",
    "data_frame = pd.read_csv('NSE-TATAGLOBAL.csv', parse_dates=['Date'], index_col='Date')\n",
    "data_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = data_scaler.fit_transform(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to create a stacked LSTM model\n",
    "def create_model(units, n_features):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(None, n_features)))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the dataset into training and testing sets\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "train_data = scaled_data[:train_size, :]\n",
    "test_data = scaled_data[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sequences and labels for the training data\n",
    "n_steps = 60\n",
    "x_train, y_train = [], []\n",
    "for i in range(n_steps, len(train_data)):\n",
    "    x_train.append(train_data[i - n_steps:i, :])\n",
    "    y_train.append(train_data[i, 0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sequences and labels for the testing data\n",
    "x_test, y_test = [], []\n",
    "for i in range(n_steps, len(test_data)):\n",
    "    x_test.append(test_data[i - n_steps:i, :])\n",
    "    y_test.append(test_data[i, 0])\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "49/49 [==============================] - 4s 23ms/step - loss: 0.0088\n",
      "Epoch 2/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 9.0796e-04\n",
      "Epoch 3/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 8.5684e-04\n",
      "Epoch 4/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 8.1638e-04\n",
      "Epoch 5/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 7.7643e-04\n",
      "Epoch 6/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 7.3040e-04\n",
      "Epoch 7/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 7.2458e-04\n",
      "Epoch 8/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 6.2525e-04\n",
      "Epoch 9/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 6.2597e-04\n",
      "Epoch 10/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 6.1855e-04\n",
      "Epoch 11/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 5.6156e-04\n",
      "Epoch 12/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 5.5069e-04\n",
      "Epoch 13/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 5.1850e-04\n",
      "Epoch 14/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 5.0925e-04\n",
      "Epoch 15/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 5.0153e-04\n",
      "Epoch 16/50\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 5.4586e-04\n",
      "Epoch 17/50\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 4.7099e-04\n",
      "Epoch 18/50\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 4.6686e-04\n",
      "Epoch 19/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.5853e-04\n",
      "Epoch 20/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.6364e-04\n",
      "Epoch 21/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 4.4879e-04\n",
      "Epoch 22/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.7657e-04\n",
      "Epoch 23/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.0372e-04\n",
      "Epoch 24/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.8542e-04\n",
      "Epoch 25/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.6841e-04\n",
      "Epoch 26/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 4.7161e-04\n",
      "Epoch 27/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.3753e-04\n",
      "Epoch 28/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 3.8440e-04\n",
      "Epoch 29/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.7650e-04\n",
      "Epoch 30/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.6207e-04\n",
      "Epoch 31/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.4449e-04\n",
      "Epoch 32/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.0057e-04\n",
      "Epoch 33/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 4.4947e-04\n",
      "Epoch 34/50\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 3.5987e-04\n",
      "Epoch 35/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 3.1981e-04\n",
      "Epoch 36/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.1363e-04\n",
      "Epoch 37/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.9369e-04\n",
      "Epoch 38/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 2.9592e-04\n",
      "Epoch 39/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.1664e-04\n",
      "Epoch 40/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 2.8208e-04\n",
      "Epoch 41/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 3.1462e-04\n",
      "Epoch 42/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.7995e-04\n",
      "Epoch 43/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 2.8063e-04\n",
      "Epoch 44/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 3.0317e-04\n",
      "Epoch 45/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.1171e-04\n",
      "Epoch 46/50\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 2.7722e-04\n",
      "Epoch 47/50\n",
      "49/49 [==============================] - 1s 23ms/step - loss: 3.0332e-04\n",
      "Epoch 48/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 3.0035e-04\n",
      "Epoch 49/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 2.8900e-04\n",
      "Epoch 50/50\n",
      "49/49 [==============================] - 1s 24ms/step - loss: 2.9102e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131ad819940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(units=50, n_features=scaled_data.shape[1])\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 15ms/step - loss: 1.4012e-04\n",
      "Mean Squared Error: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance of the model on the testing data\n",
    "mse = model.evaluate(x_test, y_test)\n",
    "print(\"Mean Squared Error: {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the testing data using the trained model\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to Inverse scale the predictions and actual values\n",
    "y_pred = data_scaler.inverse_transform(np.concatenate((y_pred, x_test[:, -1, 1:]), axis=1))[:, 0]\n",
    "y_test = data_scaler.inverse_transform(np.concatenate((y_test.reshape(-1, 1), x_test[:, -1, 1:]), axis=1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Predicted Close  Actual Close\n",
      "0   2011-12-09        90.091955         88.75\n",
      "1   2011-12-08        90.515857         90.85\n",
      "2   2011-12-07        91.027194         91.00\n",
      "3   2011-12-05        91.595391         91.70\n",
      "4   2011-12-02        92.116585         88.60\n",
      "..         ...              ...           ...\n",
      "342 2010-07-27       116.625395        117.60\n",
      "343 2010-07-26       117.316702        120.10\n",
      "344 2010-07-23       118.268563        121.80\n",
      "345 2010-07-22       119.903231        120.30\n",
      "346 2010-07-21       120.609233        122.10\n",
      "\n",
      "[347 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# And at last Printing the predicted and actual values\n",
    "predictions = pd.DataFrame({'Date': data_frame.index[train_size + n_steps:], 'Predicted Close': y_pred, 'Actual Close': y_test})\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
